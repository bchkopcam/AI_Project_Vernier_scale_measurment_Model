{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219e404d-5b7b-4640-8a4f-39b40984ef47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\bchko\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\bchko\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f88ea14-7032-4637-881c-49d148a549f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c409fd96-403b-4fb2-8c80-75810b3e9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(File_Path):\n",
    "    default_file = File_Path\n",
    "    filename = default_file\n",
    "\n",
    "    # Loads an image\n",
    "    src = cv.imread(default_file, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    #cv.imshow(\"Raw Image\", src)\n",
    "    #print(\"Raw Image Size\",np.shape(src))\n",
    "\n",
    "    # Check if image is loaded fine\n",
    "    if src is None:\n",
    "        print('Error opening image!')\n",
    "        print('Usage: hough_lines.py [image_name -- default ' + default_file + '] \\n')\n",
    "        return -1\n",
    "\n",
    "    xscale = 0.4\n",
    "    \n",
    "    yscale = 1\n",
    "    \n",
    "    src = cv.resize(src, None, fx=xscale, fy=yscale)\n",
    "\n",
    "    #cv.imshow(\"Resized Image\", src)\n",
    "    #print(\"Resized Image Size\",np.shape(src))\n",
    "    \n",
    "    src = src[int(1450*yscale):int(2100*yscale), int(800*xscale):int(2500*xscale)]\n",
    "\n",
    "    cv.imshow(\"AOI Image\", src)\n",
    "    #print(\"AOI Image Size\",np.shape(src))\n",
    "\n",
    "    \n",
    "    dst = cv.Canny(src, 150, 500, 80, 3)\n",
    "\n",
    "    # Copy edges to the images that will display the results in BGR\n",
    "    cdstP = cv.cvtColor(src, cv.COLOR_GRAY2BGR)\n",
    "    \n",
    "\n",
    "    linesP = cv.HoughLinesP(dst, 1, np.pi / 180, 20, None, 20, 5)\n",
    "\n",
    "    if linesP is not None:\n",
    "        for i in range(0, len(linesP)):\n",
    "            l = linesP[i][0]\n",
    "            cv.line(cdstP, (l[0], l[1]), (l[2], l[3]), (0, 0, 255), 1, cv.LINE_AA)\n",
    "\n",
    "    cv.imshow(filename, dst)\n",
    "    \n",
    "    cv.imshow(\"Hough_P_Image\", cdstP)\n",
    "    \n",
    "    cv.waitKey()\n",
    "    \n",
    "    if linesP is not None:\n",
    "        linesP = sorted(linesP, key=lambda x: np.sqrt((x[0][2] - x[0][0])**2 + (x[0][3] - x[0][1])**2), reverse=True)[:100]\n",
    "    else:\n",
    "        linesP = []  # If no lines are detected, initialize an empty list\n",
    "\n",
    "    return dst, linesP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ac2db-bbd8-4177-866e-b525e6ccacba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lines = Preprocess(r\"C:\\Users\\bchko\\Downloads\\CEE4990\\images\\Vernier_Scale_1_05.jpg\")\n",
    "print(np.shape(img))\n",
    "\n",
    "cv.imshow(\"Vernier_Scale_T_20.jpg\", img)\n",
    "cv.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f415eb-3050-44bc-bc31-5fb9b0d57590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "# Directory containing images\n",
    "image_directory = r\"C:\\Users\\bchko\\Downloads\\CEE4990\\images\"\n",
    "\n",
    "# List to store processed data\n",
    "dataset = np.empty(shape=(0,), dtype=[('image', object), ('label', '<U2')])\n",
    "\n",
    "# Initialize lists to store images and labels separately\n",
    "x1 = []\n",
    "x2 = []\n",
    "y = []\n",
    "\n",
    "# Iterate over each image file in the directory\n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "        # Extract the last two digits of the filename before the \".jpg\" extension\n",
    "        label = filename[-6:-4]  # Assuming the filename format is XXXXXYY.jpg\n",
    "        \n",
    "        # Construct full path to the image file\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        \n",
    "        # Preprocess the image\n",
    "        img, lines = Preprocess(image_path)\n",
    "        \n",
    "        # Append processed data to the dataset along with the label\n",
    "        dataset = np.append(dataset, np.array([(img, int(label))], dtype=dataset.dtype))\n",
    "\n",
    "        lines = np.squeeze(lines)\n",
    "\n",
    "        # Get the indices that would sort the array along the first axis based on the first value in each line\n",
    "        sorted_indices = np.argsort(lines[:, 0])\n",
    "        \n",
    "        # Reorder the lines of the array based on the sorted indices\n",
    "        Reordered_Lines = lines[sorted_indices]\n",
    "\n",
    "        Reordered_Lines[:, [0, 2]] -= Reordered_Lines[0,0]\n",
    "\n",
    "        #print(np.shape(Reordered_Lines))\n",
    "            \n",
    "        # Append image and label to x and y lists\n",
    "        #print(np.shape(lines))\n",
    "        x2.append(Reordered_Lines)\n",
    "        x1.append(img)\n",
    "        y.append(int(label))\n",
    "\n",
    "\n",
    "\n",
    "# Convert x and y lists to NumPy arrays\n",
    "x1 = np.array(x1)\n",
    "x2 = np.array(x2)\n",
    "y = np.array(y)\n",
    "\n",
    "# Now x contains the array of images, and y contains the array of labels\n",
    "\n",
    "for count, value in enumerate(y):\n",
    "    if np.shape(x2[count]) == (100,4):\n",
    "        print('good')\n",
    "    else:\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba36fe0d-f5e4-4958-ad67-1c820e708c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets with an 80-20 split\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y, test_size=0.2)\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51f1fffc-b908-41bf-8ca4-255ae22c0b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 650, 680)\n",
      "(23, 100, 4)\n",
      "(6, 650, 680)\n",
      "(6, 100, 4)\n"
     ]
    }
   ],
   "source": [
    "print (x_train1.shape) \n",
    "print (x_train2.shape) \n",
    "print (x_test1.shape) \n",
    "print (x_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19b8118d-b966-402e-86cf-ddc3dc01e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense\n",
    "\n",
    "# Define the image dimensions\n",
    "img_rows, img_cols = 650, 680  # Example image size, adjust as necessary\n",
    "\n",
    "# Create the regression model\n",
    "model_img = Sequential([\n",
    "    Input(shape=(img_rows, img_cols, 1)),  # Assuming grayscale images, hence '1' at the end for channels\n",
    "    Conv2D(50, kernel_size=3, activation='relu'),\n",
    "    Conv2D(50, kernel_size=3, activation='relu'),\n",
    "    Conv2D(40, kernel_size=3, activation='relu'),\n",
    "    Conv2D(20, kernel_size=3, activation='relu'),\n",
    "    Conv2D(20, kernel_size=3, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),  # Increase the number of units for better representation\n",
    "    Dense(100, activation='relu'), \n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression, with a single output neuron\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1da8de1-5161-4541-a28a-058b54328f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">648</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">678</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">646</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">676</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">644</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">674</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">642</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">672</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,220</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">670</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,620</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8576000</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │   <span style=\"color: #00af00; text-decoration-color: #00af00\">857,600,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m648\u001b[0m, \u001b[38;5;34m678\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │           \u001b[38;5;34m500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m646\u001b[0m, \u001b[38;5;34m676\u001b[0m, \u001b[38;5;34m50\u001b[0m)   │        \u001b[38;5;34m22,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m644\u001b[0m, \u001b[38;5;34m674\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │        \u001b[38;5;34m18,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m642\u001b[0m, \u001b[38;5;34m672\u001b[0m, \u001b[38;5;34m20\u001b[0m)   │         \u001b[38;5;34m7,220\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m, \u001b[38;5;34m670\u001b[0m, \u001b[38;5;34m20\u001b[0m)   │         \u001b[38;5;34m3,620\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8576000\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │   \u001b[38;5;34m857,600,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">857,672,331</span> (3.20 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m857,672,331\u001b[0m (3.20 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">857,672,331</span> (3.20 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m857,672,331\u001b[0m (3.20 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_img.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Print model summary\n",
    "model_img.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "607dda3c-bfcc-414a-b4ae-3922d77eca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 56s/step - loss: 96.0149 - mae: 7.6032 - val_loss: 1046344960.0000 - val_mae: 32346.6191\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 198s/step - loss: 1048997440.0000 - mae: 32381.4316 - val_loss: 12361552.0000 - val_mae: 3478.0432\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 200s/step - loss: 11744608.0000 - mae: 3400.2312 - val_loss: 465110.2500 - val_mae: 532.3168\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 242s/step - loss: 387480.3125 - mae: 501.3701 - val_loss: 147935.6406 - val_mae: 313.3823\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 188s/step - loss: 159608.9375 - mae: 342.9713 - val_loss: 404260.7500 - val_mae: 609.5380\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 268s/step - loss: 423903.6562 - mae: 631.7726 - val_loss: 641655.6250 - val_mae: 786.3173\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 242s/step - loss: 654745.3750 - mae: 798.6270 - val_loss: 712726.9375 - val_mae: 829.9392\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 181s/step - loss: 715382.5625 - mae: 836.4942 - val_loss: 631329.6875 - val_mae: 778.9197\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 318s/step - loss: 633054.3125 - mae: 785.3611 - val_loss: 462489.3438 - val_mae: 660.4183\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 225s/step - loss: 450950.4688 - mae: 658.4831 - val_loss: 249045.5156 - val_mae: 475.4853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b0ba4a2150>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_img.fit (x_train1, y_train1, epochs = 10, validation_data=(x_test1, y_test1), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e43d02-65db-479c-a425-07d3754ec2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model\n",
    "model_lines = Sequential([\n",
    "    Flatten(input_shape=(100, 4)),  # Flatten the input to a 1D array\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression with a single output neuron\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69a9df4-9390-4baa-9fd6-844c2bffc434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_lines.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "\n",
    "model_lines.fit (x_train2, y_train2)\n",
    "\n",
    "# Print model summary\n",
    "model_lines.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
